{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MultiModelCNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN+9ITdnGE5c3RaXbagD/gz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aj1365/MultiModelCNN/blob/main/MultiModelCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENi7VEVSnHhK"
      },
      "outputs": [],
      "source": [
        "######################################### Connecting to Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "######################## Your file directory in Google Drive\n",
        "\n",
        "%cd /content/drive/MyDrive/MMCNN"
      ],
      "metadata": {
        "id": "lumXfxIjnIh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras \n",
        "from tensorflow.keras.layers import Conv2D, Conv3D, Flatten, Dense, Reshape, BatchNormalization, MaxPool2D, MaxPooling1D,Add, ConvLSTM2D, LSTM, Conv1D\n",
        "from tensorflow.keras.layers import Dropout, Input\n",
        "from tensorflow.keras.models import Model\n",
        "#from keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras import backend as Kb\n",
        "from tensorflow.keras.layers import Lambda\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import add, concatenate\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "#from keras.utils.vis_utils import plot_model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "#from keras.utils import plot_model\n",
        "import tensorflow\n",
        " \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, cohen_kappa_score\n",
        " \n",
        "from sklearn.decomposition import FactorAnalysis\n",
        "from sklearn.decomposition import PCA\n",
        "from operator import truediv\n",
        " \n",
        "from plotly.offline import init_notebook_mode\n",
        " \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as sio\n",
        "import os\n",
        "#!pip install spectral\n",
        "import spectral"
      ],
      "metadata": {
        "id": "65eE0GP6nL5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## GLOBAL VARIABLES\n",
        "test_ratio = 0.5\n",
        "#windowSize = 8"
      ],
      "metadata": {
        "id": "SM21YOlzni8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loadData(name):\n",
        "    data_path = os.path.join(os.getcwd(),'Data/')\n",
        "    if name == 'BrunswickS1':\n",
        "        \n",
        "        data = sio.loadmat(os.path.join(data_path, 'BrunswickS1.mat'))['BrunswickS1']\n",
        "        labels = sio.loadmat(os.path.join(data_path, 'Brunswick_gt.mat'))['Brunswick_gt']\n",
        "\n",
        "     else if name == 'BrunswickS2':\n",
        "        \n",
        "        data = sio.loadmat(os.path.join(data_path, 'BrunswickS2.mat'))['BrunswickS2]\n",
        "        labels = sio.loadmat(os.path.join(data_path, 'Brunswick_gt.mat'))['Brunswick_gt']\n",
        "\n",
        "     else if name == 'BrunswickDEM':\n",
        "        \n",
        "        data = sio.loadmat(os.path.join(data_path, 'BrunswickDEM.mat'))['BrunswickDEM]\n",
        "        labels = sio.loadmat(os.path.join(data_path, 'Brunswick_gt.mat'))['Brunswick_gt']\n",
        "\n",
        "\n",
        "    return data, labels"
      ],
      "metadata": {
        "id": "VeYHMgFNnl3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def splitTrainTestSet(X, y, testRatio, randomState=345):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testRatio, random_state=randomState,\n",
        "                                                        stratify=y)\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "VaYeGGDKnvZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def padWithZeros(X, margin=2):\n",
        "    newX = np.zeros((X.shape[0] + 2 * margin, X.shape[1] + 2* margin, X.shape[2]))\n",
        "    x_offset = margin\n",
        "    y_offset = margin\n",
        "    newX[x_offset:X.shape[0] + x_offset, y_offset:X.shape[1] + y_offset, :] = X\n",
        "    return newX"
      ],
      "metadata": {
        "id": "FWzvHIR_nzHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def createImageCubes(X, y, windowSize=8, removeZeroLabels = True):\n",
        "    margin = int((windowSize) / 2)\n",
        "    zeroPaddedX = padWithZeros(X, margin=margin)\n",
        "    # split patches\n",
        "    patchesData = np.zeros((X.shape[0] * X.shape[1], windowSize, windowSize, X.shape[2]))\n",
        "    patchesLabels = np.zeros((X.shape[0] * X.shape[1]))\n",
        "    patchIndex = 0\n",
        "    for r in range(margin, zeroPaddedX.shape[0] - margin):\n",
        "        for c in range(margin, zeroPaddedX.shape[1] - margin):\n",
        "            patch = zeroPaddedX[r - margin:r + margin , c - margin:c + margin ]   \n",
        "            patchesData[patchIndex, :, :, :] = patch\n",
        "            patchesLabels[patchIndex] = y[r-margin, c-margin]\n",
        "            patchIndex = patchIndex + 1\n",
        "    if removeZeroLabels:\n",
        "        patchesData = patchesData[patchesLabels>0,:,:,:]\n",
        "        patchesLabels = patchesLabels[patchesLabels>0]\n",
        "        patchesLabels -= 1\n",
        "    return patchesData, patchesLabels"
      ],
      "metadata": {
        "id": "MSHKmHhgn0_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = 'BrunswickS2'\n",
        "X, y = loadData(dataset)\n",
        "\n",
        "X=(X-np.min(X))/(np.max(X)-np.min(X))\n",
        "X.shape, y.shape"
      ],
      "metadata": {
        "id": "0WSk6mS2n2yQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = 'BrunswickS1'\n",
        "X1, y = loadData(dataset)\n",
        "\n",
        "X1=(X1-np.min(X1))/(np.max(X1)-np.min(X1))\n",
        "X1.shape, y.shape"
      ],
      "metadata": {
        "id": "6P-6_AHCn5Dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = 'BrunswickDEM'\n",
        "X2, y = loadData(dataset)\n",
        "\n",
        "X2=(X2-np.min(X2))/(np.max(X2)-np.min(X2))\n",
        "\n",
        "X2=X2.reshape(667, 2323,1)\n",
        "X2.shape, y.shape\n"
      ],
      "metadata": {
        "id": "jpolBnVKn9mJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X11, y1 = createImageCubes(X, y, windowSize=4)\n",
        "\n",
        "X11.shape, y1.shape"
      ],
      "metadata": {
        "id": "l04lJztSorNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X12, y2 = createImageCubes(X1, y, windowSize=8)\n",
        "\n",
        "X12.shape, y2.shape"
      ],
      "metadata": {
        "id": "qRrVDEt2oznM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X12 = X12.reshape((X12.shape[0],8,8,4,1))\n",
        "X12.shape"
      ],
      "metadata": {
        "id": "aE5BF5UHo1W_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X13, y3 = createImageCubes(X2, y, windowSize=8)\n",
        "\n",
        "X13.shape, y3.shape"
      ],
      "metadata": {
        "id": "iWvELGi0o1aP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X1train, X1test, y1train, y1test = splitTrainTestSet(X11, y1, test_ratio)\n",
        "\n",
        "X1train.shape, X1test.shape, y1train.shape, y1test.shape\n",
        "\n"
      ],
      "metadata": {
        "id": "qKwiPQy6o56z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X2train, X2test, y2train, y2test = splitTrainTestSet(X12, y2, test_ratio)\n",
        "\n",
        "X2train.shape, X2test.shape, y2train.shape, y2test.shape\n"
      ],
      "metadata": {
        "id": "YHyFe53Ko59-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X3train, X3test, y3train, y3test = splitTrainTestSet(X13, y3, test_ratio)\n",
        "\n",
        "X3train.shape, X3test.shape, y3train.shape, y3test.shape\n"
      ],
      "metadata": {
        "id": "HKC7Kzzxo6BL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ytrain = tensorflow.keras.utils.to_categorical(y1train)\n",
        "ytrain.shape\n"
      ],
      "metadata": {
        "id": "lZ_dCS5Po6EM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_units = 11 "
      ],
      "metadata": {
        "id": "77-zFmR6o6HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow import keras\n"
      ],
      "metadata": {
        "id": "xcUnXGwao1dN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "BnucHzkHo1gb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######################## Swin Transformer settings (Try to change it)\n",
        "\n",
        "input_shape = (8, 8, 1)\n",
        "patch_size = (2, 2)  # 2-by-2 sized patches\n",
        "dropout_rate = 0.03  # Dropout rate\n",
        "num_heads = 8  # Attention heads\n",
        "embed_dim = 64  # Embedding dimension\n",
        "num_mlp = 256  # MLP layer size\n",
        "qkv_bias = True  # Convert embedded patches to query, key, and values with a learnable additive value\n",
        "window_size = 2  # Size of attention window\n",
        "shift_size = 1  # Size of shifting window\n",
        "image_dimension = 8  # Initial image size\n",
        "\n",
        "num_patch_x = input_shape[0] // patch_size[0]\n",
        "num_patch_y = input_shape[1] // patch_size[1]\n"
      ],
      "metadata": {
        "id": "mpVRHCLvorUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def window_partition(x, window_size):\n",
        "    _, height, width, channels = x.shape\n",
        "    patch_num_y = height // window_size\n",
        "    patch_num_x = width // window_size\n",
        "    x = tf.reshape(\n",
        "        x, shape=(-1, patch_num_y, window_size, patch_num_x, window_size, channels)\n",
        "    )\n",
        "    x = tf.transpose(x, (0, 1, 3, 2, 4, 5))\n",
        "    windows = tf.reshape(x, shape=(-1, window_size, window_size, channels))\n",
        "    return windows\n",
        "\n",
        "\n",
        "def window_reverse(windows, window_size, height, width, channels):\n",
        "    patch_num_y = height // window_size\n",
        "    patch_num_x = width // window_size\n",
        "    x = tf.reshape(\n",
        "        windows,\n",
        "        shape=(-1, patch_num_y, patch_num_x, window_size, window_size, channels),\n",
        "    )\n",
        "    x = tf.transpose(x, perm=(0, 1, 3, 2, 4, 5))\n",
        "    x = tf.reshape(x, shape=(-1, height, width, channels))\n",
        "    return x\n",
        "\n",
        "\n",
        "class DropPath(layers.Layer):\n",
        "    def __init__(self, drop_prob=None, **kwargs):\n",
        "        super(DropPath, self).__init__(**kwargs)\n",
        "        self.drop_prob = drop_prob\n",
        "\n",
        "    def call(self, x):\n",
        "        input_shape = tf.shape(x)\n",
        "        batch_size = input_shape[0]\n",
        "        rank = x.shape.rank\n",
        "        shape = (batch_size,) + (1,) * (rank - 1)\n",
        "        random_tensor = (1 - self.drop_prob) + tf.random.uniform(shape, dtype=x.dtype)\n",
        "        path_mask = tf.floor(random_tensor)\n",
        "        output = tf.math.divide(x, 1 - self.drop_prob) * path_mask\n",
        "        return output"
      ],
      "metadata": {
        "id": "IzYwvRhJorXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WindowAttention(layers.Layer):\n",
        "    def __init__(\n",
        "        self, dim, window_size, num_heads, qkv_bias=True, dropout_rate=0.0, **kwargs\n",
        "    ):\n",
        "        super(WindowAttention, self).__init__(**kwargs)\n",
        "        self.dim = dim\n",
        "        self.window_size = window_size\n",
        "        self.num_heads = num_heads\n",
        "        self.scale = (dim // num_heads) ** -0.5\n",
        "        self.qkv = layers.Dense(dim * 3, use_bias=qkv_bias)\n",
        "        self.dropout = layers.Dropout(dropout_rate)\n",
        "        self.proj = layers.Dense(dim)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        num_window_elements = (2 * self.window_size[0] - 1) * (\n",
        "            2 * self.window_size[1] - 1\n",
        "        )\n",
        "        self.relative_position_bias_table = self.add_weight(\n",
        "            shape=(num_window_elements, self.num_heads),\n",
        "            initializer=tf.initializers.Zeros(),\n",
        "            trainable=True,\n",
        "        )\n",
        "        coords_h = np.arange(self.window_size[0])\n",
        "        coords_w = np.arange(self.window_size[1])\n",
        "        coords_matrix = np.meshgrid(coords_h, coords_w, indexing=\"ij\")\n",
        "        coords = np.stack(coords_matrix)\n",
        "        coords_flatten = coords.reshape(2, -1)\n",
        "        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n",
        "        relative_coords = relative_coords.transpose([1, 2, 0])\n",
        "        relative_coords[:, :, 0] += self.window_size[0] - 1\n",
        "        relative_coords[:, :, 1] += self.window_size[1] - 1\n",
        "        relative_coords[:, :, 0] *= 2 * self.window_size[1] - 1\n",
        "        relative_position_index = relative_coords.sum(-1)\n",
        "\n",
        "        self.relative_position_index = tf.Variable(\n",
        "            initial_value=tf.convert_to_tensor(relative_position_index), trainable=False\n",
        "        )\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        _, size, channels = x.shape\n",
        "        head_dim = channels // self.num_heads\n",
        "        x_qkv = self.qkv(x)\n",
        "        x_qkv = tf.reshape(x_qkv, shape=(-1, size, 3, self.num_heads, head_dim))\n",
        "        x_qkv = tf.transpose(x_qkv, perm=(2, 0, 3, 1, 4))\n",
        "        q, k, v = x_qkv[0], x_qkv[1], x_qkv[2]\n",
        "        q = q * self.scale\n",
        "        k = tf.transpose(k, perm=(0, 1, 3, 2))\n",
        "        attn = q @ k\n",
        "\n",
        "        num_window_elements = self.window_size[0] * self.window_size[1]\n",
        "        relative_position_index_flat = tf.reshape(\n",
        "            self.relative_position_index, shape=(-1,)\n",
        "        )\n",
        "        relative_position_bias = tf.gather(\n",
        "            self.relative_position_bias_table, relative_position_index_flat\n",
        "        )\n",
        "        relative_position_bias = tf.reshape(\n",
        "            relative_position_bias, shape=(num_window_elements, num_window_elements, -1)\n",
        "        )\n",
        "        relative_position_bias = tf.transpose(relative_position_bias, perm=(2, 0, 1))\n",
        "        attn = attn + tf.expand_dims(relative_position_bias, axis=0)\n",
        "\n",
        "        if mask is not None:\n",
        "            nW = mask.get_shape()[0]\n",
        "            mask_float = tf.cast(\n",
        "                tf.expand_dims(tf.expand_dims(mask, axis=1), axis=0), tf.float32\n",
        "            )\n",
        "            attn = (\n",
        "                tf.reshape(attn, shape=(-1, nW, self.num_heads, size, size))\n",
        "                + mask_float\n",
        "            )\n",
        "            attn = tf.reshape(attn, shape=(-1, self.num_heads, size, size))\n",
        "            attn = keras.activations.softmax(attn, axis=-1)\n",
        "        else:\n",
        "            attn = keras.activations.softmax(attn, axis=-1)\n",
        "        attn = self.dropout(attn)\n",
        "\n",
        "        x_qkv = attn @ v\n",
        "        x_qkv = tf.transpose(x_qkv, perm=(0, 2, 1, 3))\n",
        "        x_qkv = tf.reshape(x_qkv, shape=(-1, size, channels))\n",
        "        x_qkv = self.proj(x_qkv)\n",
        "        x_qkv = self.dropout(x_qkv)\n",
        "        return x_qkv"
      ],
      "metadata": {
        "id": "Qr2KOkIApLQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SwinTransformer(layers.Layer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim,\n",
        "        num_patch,\n",
        "        num_heads,\n",
        "        window_size=7,\n",
        "        shift_size=0,\n",
        "        num_mlp=1024,\n",
        "        qkv_bias=True,\n",
        "        dropout_rate=0.0,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super(SwinTransformer, self).__init__(**kwargs)\n",
        "\n",
        "        self.dim = dim  # number of input dimensions\n",
        "        self.num_patch = num_patch  # number of embedded patches\n",
        "        self.num_heads = num_heads  # number of attention heads\n",
        "        self.window_size = window_size  # size of window\n",
        "        self.shift_size = shift_size  # size of window shift\n",
        "        self.num_mlp = num_mlp  # number of MLP nodes\n",
        "\n",
        "        self.norm1 = layers.LayerNormalization(epsilon=1e-5)\n",
        "        self.attn = WindowAttention(\n",
        "            dim,\n",
        "            window_size=(self.window_size, self.window_size),\n",
        "            num_heads=num_heads,\n",
        "            qkv_bias=qkv_bias,\n",
        "            dropout_rate=dropout_rate,\n",
        "        )\n",
        "        self.drop_path = DropPath(dropout_rate)\n",
        "        self.norm2 = layers.LayerNormalization(epsilon=1e-5)\n",
        "\n",
        "        self.mlp = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(num_mlp),\n",
        "                layers.Activation(keras.activations.gelu),\n",
        "                layers.Dropout(dropout_rate),\n",
        "                layers.Dense(dim),\n",
        "                layers.Dropout(dropout_rate),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        if min(self.num_patch) < self.window_size:\n",
        "            self.shift_size = 0\n",
        "            self.window_size = min(self.num_patch)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        if self.shift_size == 0:\n",
        "            self.attn_mask = None\n",
        "        else:\n",
        "            height, width = self.num_patch\n",
        "            h_slices = (\n",
        "                slice(0, -self.window_size),\n",
        "                slice(-self.window_size, -self.shift_size),\n",
        "                slice(-self.shift_size, None),\n",
        "            )\n",
        "            w_slices = (\n",
        "                slice(0, -self.window_size),\n",
        "                slice(-self.window_size, -self.shift_size),\n",
        "                slice(-self.shift_size, None),\n",
        "            )\n",
        "            mask_array = np.zeros((1, height, width, 1))\n",
        "            count = 0\n",
        "            for h in h_slices:\n",
        "                for w in w_slices:\n",
        "                    mask_array[:, h, w, :] = count\n",
        "                    count += 1\n",
        "            mask_array = tf.convert_to_tensor(mask_array)\n",
        "\n",
        "            # mask array to windows\n",
        "            mask_windows = window_partition(mask_array, self.window_size)\n",
        "            mask_windows = tf.reshape(\n",
        "                mask_windows, shape=[-1, self.window_size * self.window_size]\n",
        "            )\n",
        "            attn_mask = tf.expand_dims(mask_windows, axis=1) - tf.expand_dims(\n",
        "                mask_windows, axis=2\n",
        "            )\n",
        "            attn_mask = tf.where(attn_mask != 0, -100.0, attn_mask)\n",
        "            attn_mask = tf.where(attn_mask == 0, 0.0, attn_mask)\n",
        "            self.attn_mask = tf.Variable(initial_value=attn_mask, trainable=False)\n",
        "\n",
        "    def call(self, x):\n",
        "        height, width = self.num_patch\n",
        "        _, num_patches_before, channels = x.shape\n",
        "        x_skip = x\n",
        "        x = self.norm1(x)\n",
        "        x = tf.reshape(x, shape=(-1, height, width, channels))\n",
        "        if self.shift_size > 0:\n",
        "            shifted_x = tf.roll(\n",
        "                x, shift=[-self.shift_size, -self.shift_size], axis=[1, 2]\n",
        "            )\n",
        "        else:\n",
        "            shifted_x = x\n",
        "\n",
        "        x_windows = window_partition(shifted_x, self.window_size)\n",
        "        x_windows = tf.reshape(\n",
        "            x_windows, shape=(-1, self.window_size * self.window_size, channels)\n",
        "        )\n",
        "        attn_windows = self.attn(x_windows, mask=self.attn_mask)\n",
        "\n",
        "        attn_windows = tf.reshape(\n",
        "            attn_windows, shape=(-1, self.window_size, self.window_size, channels)\n",
        "        )\n",
        "        shifted_x = window_reverse(\n",
        "            attn_windows, self.window_size, height, width, channels\n",
        "        )\n",
        "        if self.shift_size > 0:\n",
        "            x = tf.roll(\n",
        "                shifted_x, shift=[self.shift_size, self.shift_size], axis=[1, 2]\n",
        "            )\n",
        "        else:\n",
        "            x = shifted_x\n",
        "\n",
        "        x = tf.reshape(x, shape=(-1, height * width, channels))\n",
        "        x = self.drop_path(x)\n",
        "        x = x_skip + x\n",
        "        x_skip = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.mlp(x)\n",
        "        x = self.drop_path(x)\n",
        "        x = x_skip + x\n",
        "        return x"
      ],
      "metadata": {
        "id": "Xq2ybc1spLTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchExtract(layers.Layer):\n",
        "    def __init__(self, patch_size, **kwargs):\n",
        "        super(PatchExtract, self).__init__(**kwargs)\n",
        "        self.patch_size_x = patch_size[0]\n",
        "        self.patch_size_y = patch_size[0]\n",
        "\n",
        "    def call(self, images):\n",
        "        batch_size = tf.shape(images)[0]\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=images,\n",
        "            sizes=(1, self.patch_size_x, self.patch_size_y, 1),\n",
        "            strides=(1, self.patch_size_x, self.patch_size_y, 1),\n",
        "            rates=(1, 1, 1, 1),\n",
        "            padding=\"VALID\",\n",
        "        )\n",
        "        patch_dim = patches.shape[-1]\n",
        "        patch_num = patches.shape[1]\n",
        "        return tf.reshape(patches, (batch_size, patch_num * patch_num, patch_dim))\n",
        "\n",
        "\n",
        "class PatchEmbedding(layers.Layer):\n",
        "    def __init__(self, num_patch, embed_dim, **kwargs):\n",
        "        super(PatchEmbedding, self).__init__(**kwargs)\n",
        "        self.num_patch = num_patch\n",
        "        self.proj = layers.Dense(embed_dim)\n",
        "        self.pos_embed = layers.Embedding(input_dim=num_patch, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, patch):\n",
        "        pos = tf.range(start=0, limit=self.num_patch, delta=1)\n",
        "        return self.proj(patch) + self.pos_embed(pos)\n",
        "\n",
        "\n",
        "class PatchMerging(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_patch, embed_dim):\n",
        "        super(PatchMerging, self).__init__()\n",
        "        self.num_patch = num_patch\n",
        "        self.embed_dim = embed_dim\n",
        "        self.linear_trans = layers.Dense(2 * embed_dim, use_bias=False)\n",
        "\n",
        "    def call(self, x):\n",
        "        height, width = self.num_patch\n",
        "        _, _, C = x.get_shape().as_list()\n",
        "        x = tf.reshape(x, shape=(-1, height, width, C))\n",
        "        x0 = x[:, 0::2, 0::2, :]\n",
        "        x1 = x[:, 1::2, 0::2, :]\n",
        "        x2 = x[:, 0::2, 1::2, :]\n",
        "        x3 = x[:, 1::2, 1::2, :]\n",
        "        x = tf.concat((x0, x1, x2, x3), axis=-1)\n",
        "        x = tf.reshape(x, shape=(-1, (height // 2) * (width // 2), 4 * C))\n",
        "        return self.linear_trans(x)"
      ],
      "metadata": {
        "id": "xCc1323NpLWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_cnn_model():\n",
        " \n",
        "    input_shape1 =  4, 4, 12\n",
        "    input_shape2 =  8, 8, 4,1\n",
        "    input_shape3 =  8, 8, 1\n",
        "    \n",
        " \n",
        "    input1_ = Input(shape=input_shape1)\n",
        "    input2_ = Input(shape=input_shape2)\n",
        "    input3_ = Input(shape=input_shape3)\n",
        "\n",
        "    \n",
        "\n",
        "############################                   Modified VGG-16 CNN Module (Filter numbers and kernel sizes are changed)\n",
        "###########        (It shoud be noted that the kernel sizes for Conv2D in the original VGG-16 are 3 by 3, kernel_size=(3,3))\n",
        "    \n",
        "    conv_layer1 = Conv2D(filters=32, kernel_size=(1,1), activation='relu',padding='same')(input1_)\n",
        "    conv_layer2 = Conv2D(filters=32, kernel_size=(3,3), activation='relu',padding='same')(conv_layer1)\n",
        "    conv_layer3 = MaxPool2D(pool_size=(1,1))(conv_layer2)\n",
        "    \n",
        "    conv_layer4 = Conv2D(filters=64, kernel_size=(1,1), activation='relu',padding='same')(conv_layer3)\n",
        "    conv_layer5 = Conv2D(filters=64, kernel_size=(3,3), activation='relu',padding='same')(conv_layer4)\n",
        "    conv_layer6 = MaxPool2D(pool_size=(1,1))(conv_layer5)\n",
        "    \n",
        "    conv_layer7 = Conv2D(filters=64, kernel_size=(1,1), activation='relu',padding='same')(conv_layer6)\n",
        "    conv_layer8 = Conv2D(filters=64, kernel_size=(1,1), activation='relu',padding='same')(conv_layer7)\n",
        "    conv_layer9 = Conv2D(filters=64, kernel_size=(3,3), activation='relu',padding='same')(conv_layer8)\n",
        "    conv_layer10 = MaxPool2D(pool_size=(1,1))(conv_layer9)\n",
        "    \n",
        "    conv_layer11 = Conv2D(filters=64, kernel_size=(1,1), activation='relu',padding='same')(conv_layer10)\n",
        "    conv_layer12 = Conv2D(filters=64, kernel_size=(1,1), activation='relu',padding='same')(conv_layer11)\n",
        "    conv_layer13 = Conv2D(filters=64, kernel_size=(3,3), activation='relu',padding='same')(conv_layer12)\n",
        "    conv_layer14 = MaxPool2D(pool_size=(1,1))(conv_layer13)\n",
        "    \n",
        "    conv_layer15 = Conv2D(filters=128, kernel_size=(1,1), activation='relu',padding='same')(conv_layer14)\n",
        "    conv_layer16 = Conv2D(filters=128, kernel_size=(1,1), activation='relu',padding='same')(conv_layer15)\n",
        "    conv_layer17 = Conv2D(filters=128, kernel_size=(3,3), activation='relu',padding='same')(conv_layer16)\n",
        "    conv_layer18 = MaxPool2D(pool_size=(1,1))(conv_layer17)\n",
        "    \n",
        "  \n",
        " ###########################################################\n",
        "######################  3D CNN\n",
        "   \n",
        "   \n",
        "\n",
        "    conv_layerb1 = Conv3D(filters=64, kernel_size=(2, 2, 2), activation='relu', padding='same', name='conv1')(input2_)\n",
        "    norm_1 = BatchNormalization(name='norm_a1')(conv_layerb1)\n",
        "    conv_layerb2 = Conv3D(filters=64, kernel_size=(3, 3, 3), activation='relu',padding='same', name='conv2')(norm_1)\n",
        " \n",
        "    \n",
        "    conv3d_shape = conv_layerb2.shape\n",
        "    conv_layerb2 = Reshape((conv3d_shape[1], conv3d_shape[2], conv3d_shape[3]*conv3d_shape[4]))(conv_layerb2)\n",
        "\n",
        "    conv_layerb3 = Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same', name='conv3')(conv_layerb2)\n",
        "\n",
        "    max_b_2 = MaxPool2D((2,2), strides=(2,2), padding='same')(conv_layerb3)\n",
        "   \n",
        " #################################### \n",
        "    ############################### concate first  CNN to Second  CNN\n",
        "    \n",
        "    concate_level_1 = concatenate([conv_layer18, max_b_2])\n",
        "    conv_c2 = Conv2D(32, kernel_size=(1, 1), padding='same', name='conv_2')(concate_level_1)\n",
        "    norm_c2 = BatchNormalization(name='norm_2')(conv_c2)\n",
        "    relu_c2 = Activation('relu', name='relu_2')(norm_c2)\n",
        "\n",
        " \n",
        "    pool_e_1 = AveragePooling2D(pool_size=(2, 2), strides=1, padding='same', name='avg_pool_5_1')(relu_c2)\n",
        "    \n",
        "\n",
        "    flatten_1=Flatten()(pool_e_1)\n",
        "    \n",
        "    dense_layer1 = Dense(units=100, activation='relu')(flatten_1)\n",
        "    dense_layer1 = Dropout(0.4)(dense_layer1)\n",
        "    dense_layer2 = Dense(units=50, activation='relu')(dense_layer1)\n",
        "    dense_layer2 = Dropout(0.4)(dense_layer2)\n",
        "    \n",
        "    ######################################## Swin Transformer\n",
        "    \n",
        "    x = layers.RandomCrop(image_dimension, image_dimension)(input3_)\n",
        "    x = layers.RandomFlip(\"horizontal\")(x)\n",
        "    x = PatchExtract(patch_size)(x)\n",
        "    x = PatchEmbedding(num_patch_x * num_patch_y, embed_dim)(x)\n",
        "    x = SwinTransformer(\n",
        "    dim=embed_dim,\n",
        "    num_patch=(num_patch_x, num_patch_y),\n",
        "    num_heads=num_heads,\n",
        "    window_size=window_size,\n",
        "    shift_size=0,\n",
        "    num_mlp=num_mlp,\n",
        "    qkv_bias=qkv_bias,\n",
        "    dropout_rate=dropout_rate,\n",
        "     )(x)\n",
        "    x = SwinTransformer(\n",
        "    dim=embed_dim,\n",
        "    num_patch=(num_patch_x, num_patch_y),\n",
        "    num_heads=num_heads,\n",
        "    window_size=window_size,\n",
        "    shift_size=shift_size,\n",
        "    num_mlp=num_mlp,\n",
        "    qkv_bias=qkv_bias,\n",
        "    dropout_rate=dropout_rate,\n",
        "     )(x)\n",
        "    x = PatchMerging((num_patch_x, num_patch_y), embed_dim=embed_dim)(x)\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "    x = layers.Dense(50, activation=\"softmax\")(x)\n",
        "    \n",
        "    #############################################\n",
        "    concate_level_3 = concatenate([x, dense_layer2])\n",
        "\n",
        "    output_layer = Dense(units=output_units, activation='softmax')(concate_level_3)\n",
        " \n",
        "    model = Model(inputs=[input1_,input2_,input3_], outputs=output_layer)\n",
        "    model.summary()\n",
        "    \n",
        "    plot_model(model, to_file='CNN_TransformersBrunswick-VGG16.png', show_shapes=True, show_layer_names=True)\n",
        " \n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "plFfnSH-pLZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_cnn_model()"
      ],
      "metadata": {
        "id": "Xhr3NS00pLb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\"VGG16.h5\",save_best_only=True)\n",
        "history = model.fit(x=[X1train,X2train,X3train], y=ytrain, batch_size = 32, epochs=100,callbacks=model_checkpoint_callback)\n"
      ],
      "metadata": {
        "id": "HuJEpoiyorbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(7,7)) \n",
        "plt.grid() \n",
        "plt.plot(history.history['loss'])\n",
        "\n",
        "plt.savefig('BrunswickLoss-VGG16.tiff',facecolor='w', dpi=500)"
      ],
      "metadata": {
        "id": "Kw188TyZordq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X1test = X1test.reshape(-1, 4, 4, 12)\n",
        "X2test = X2test.reshape(-1, 8, 8, 4,1)\n",
        "X3test = X3test.reshape(-1, 8, 8, 1)\n",
        "\n",
        "X1test.shape,X2test.shape,X3test.shape"
      ],
      "metadata": {
        "id": "CszPX3l6pcmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ytest = np_utils.to_categorical(y1test)\n",
        "\n",
        "ytest.shape"
      ],
      "metadata": {
        "id": "V8RbreGkpcpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred_test = model.predict([X1test,X2test,X3test])\n",
        "y_pred_test = np.argmax(Y_pred_test, axis=1)\n"
      ],
      "metadata": {
        "id": "vRzNtIMHpcsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ca = np.sum(y_pred_test == np.argmax(ytest, axis=1)) / ytest.shape[0]\n",
        "\n",
        "print(\"Classification accuracy: %.5f\" % ca)"
      ],
      "metadata": {
        "id": "AYywssLypcvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classification = classification_report(np.argmax(ytest, axis=1), y_pred_test)\n",
        "print(classification)"
      ],
      "metadata": {
        "id": "tClCFVDQorgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "V17zCcRXplKt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}